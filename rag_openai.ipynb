{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-06-19T05:58:13.887130Z",
     "start_time": "2025-06-19T05:58:10.035179Z"
    }
   },
   "source": [
    "# imports\n",
    "\n",
    "import os\n",
    "import glob\n",
    "from dotenv import load_dotenv\n",
    "import gradio as gr"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\SaaSProject\\chatbot\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-19T05:58:16.625881Z",
     "start_time": "2025-06-19T05:58:13.891143Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# imports for langchain\n",
    "\n",
    "from langchain.document_loaders import DirectoryLoader, TextLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter, RecursiveCharacterTextSplitter\n",
    "from langchain.schema import Document\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "# from langchain_chroma import Chroma\n",
    "from langchain.vectorstores import FAISS\n",
    "import numpy as np\n",
    "from sklearn.manifold import TSNE\n",
    "import plotly.graph_objects as go\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import ConversationalRetrievalChain"
   ],
   "id": "b1d35c08da9d5c72",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-19T05:58:16.879433Z",
     "start_time": "2025-06-19T05:58:16.875285Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# price is a factor for our company, so we're going to use a low cost model\n",
    "\n",
    "MODEL = \"gpt-4o-mini\"\n",
    "db_name = \"vector_db\""
   ],
   "id": "143ef58d463084df",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-19T05:58:16.891354Z",
     "start_time": "2025-06-19T05:58:16.886976Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load environment variables in a file called .env\n",
    "\n",
    "load_dotenv()\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv('OPENAI_API_KEY', 'your-key-if-not-using-env')"
   ],
   "id": "4c969035c0c9090",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-19T05:58:16.916760Z",
     "start_time": "2025-06-19T05:58:16.900762Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Read in documents using LangChain's loaders\n",
    "# Take everything in all the sub-folders of our knowledgebase\n",
    "\n",
    "folders = glob.glob(\"knowledge-base/*\")\n",
    "\n",
    "# With thanks to CG and Jon R, students on the course, for this fix needed for some users\n",
    "text_loader_kwargs = {'encoding': 'utf-8'}\n",
    "# If that doesn't work, some Windows users might need to uncomment the next line instead\n",
    "# text_loader_kwargs={'autodetect_encoding': True}\n",
    "\n",
    "documents = []\n",
    "for folder in folders:\n",
    "    doc_type = os.path.basename(folder)\n",
    "    loader = DirectoryLoader(folder, glob=\"**/*.md\", loader_cls=TextLoader, loader_kwargs=text_loader_kwargs)\n",
    "    folder_docs = loader.load()\n",
    "    for doc in folder_docs:\n",
    "        doc.metadata[\"doc_type\"] = doc_type\n",
    "        documents.append(doc)"
   ],
   "id": "cf73d58c08927643",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-19T05:58:16.931469Z",
     "start_time": "2025-06-19T05:58:16.924878Z"
    }
   },
   "cell_type": "code",
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200\n",
    ")\n",
    "chunks = text_splitter.split_documents(documents)"
   ],
   "id": "778df1689f0601a0",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-19T05:58:16.946922Z",
     "start_time": "2025-06-19T05:58:16.939538Z"
    }
   },
   "cell_type": "code",
   "source": "len(chunks)",
   "id": "18597049026f8825",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "123"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-19T05:58:16.966163Z",
     "start_time": "2025-06-19T05:58:16.962134Z"
    }
   },
   "cell_type": "code",
   "source": [
    "doc_types = set(chunk.metadata['doc_type'] for chunk in chunks)\n",
    "print(f\"Document types found: {', '.join(doc_types)}\")"
   ],
   "id": "6484c32555f9823b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document types found: company, contracts, employees, products\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-19T05:58:19.783347Z",
     "start_time": "2025-06-19T05:58:16.971718Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Put the chunks of data into a Vector Store that associates a Vector Embedding with each chunk\n",
    "# Chroma is a popular open source Vector Database based on SQLLite\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "# Create vectorstore\n",
    "\n",
    "# BEFORE\n",
    "# vectorstore = Chroma.from_documents(documents=chunks, embedding=embeddings, persist_directory=db_name)\n",
    "\n",
    "# AFTER\n",
    "vectorstore = FAISS.from_documents(chunks, embedding=embeddings)\n",
    "\n",
    "total_vectors = vectorstore.index.ntotal\n",
    "dimensions = vectorstore.index.d\n",
    "\n",
    "print(f\"There are {total_vectors} vectors with {dimensions:,} dimensions in the vector store\")"
   ],
   "id": "667cc8166ab5afe5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 123 vectors with 1,536 dimensions in the vector store\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-19T05:58:20.444765Z",
     "start_time": "2025-06-19T05:58:19.791428Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# create a new Chat with OpenAI\n",
    "llm = ChatOpenAI(temperature=0.7, model_name=MODEL)\n",
    "\n",
    "# set up the conversation memory for the chat\n",
    "memory = ConversationBufferMemory(memory_key='chat_history', return_messages=True)\n",
    "\n",
    "# the retriever is an abstraction over the VectorStore that will be used during RAG\n",
    "retriever = vectorstore.as_retriever(search_type=\"mmr\", search_kwargs={\"k\": 5})\n",
    "\n",
    "# putting it together: set up the conversation chain with the GPT 3.5 LLM, the vector store and memory\n",
    "conversation_chain = ConversationalRetrievalChain.from_llm(llm=llm, retriever=retriever, memory=memory)"
   ],
   "id": "c3662dddaa925012",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_29116\\126984216.py:5: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferMemory(memory_key='chat_history', return_messages=True)\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-19T05:58:23.414200Z",
     "start_time": "2025-06-19T05:58:20.526636Z"
    }
   },
   "cell_type": "code",
   "source": [
    "query = \"Can you describe Insurellm in a few sentences\"\n",
    "result = conversation_chain.invoke({\"question\":query})\n",
    "print(result[\"answer\"])"
   ],
   "id": "d443986f616f52e1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Insurellm is an insurance tech startup founded by Avery Lancaster in 2015, aimed at innovating the insurance industry. Its first product, Markellm, connects consumers with insurance providers and has led to rapid expansion, reaching 200 employees and 12 offices across the US by 2024. The company focuses on developing advanced products such as AI-powered risk assessment and dynamic pricing models to enhance the insurance experience.\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-19T05:58:23.493240Z",
     "start_time": "2025-06-19T05:58:23.489889Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Wrapping that in a function\n",
    "\n",
    "def chat(message, history):\n",
    "    result = conversation_chain.invoke({\"question\": message})\n",
    "    return result[\"answer\"]"
   ],
   "id": "feb6a893d809a1c3",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-19T05:58:37.515163Z",
     "start_time": "2025-06-19T05:58:36.582617Z"
    }
   },
   "cell_type": "code",
   "source": "view = gr.ChatInterface(chat).launch(inbrowser=True)",
   "id": "38f20b8b96663420",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\SaaSProject\\chatbot\\.venv\\Lib\\site-packages\\gradio\\chat_interface.py:339: UserWarning: The 'tuples' format for chatbot messages is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style 'role' and 'content' keys.\n",
      "  self.chatbot = Chatbot(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7862\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7862/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-19T05:58:24.175406Z",
     "start_time": "2025-06-19T05:58:24.172421Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "24666c2f443a7519",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
