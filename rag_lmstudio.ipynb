{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-01T12:32:54.261136Z",
     "start_time": "2025-07-01T12:32:41.884839Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "import os\n",
    "import glob\n",
    "from dotenv import load_dotenv\n",
    "from langchain.document_loaders import DirectoryLoader, TextLoader\n",
    "# imports for langchain\n",
    "\n",
    "from langchain.text_splitter import CharacterTextSplitter, RecursiveCharacterTextSplitter\n",
    "from langchain.schema import Document\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "# from langchain_chroma import Chroma\n",
    "from langchain.vectorstores import FAISS\n",
    "import numpy as np\n",
    "from sklearn.manifold import TSNE\n",
    "import plotly.graph_objects as go\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "import requests"
   ],
   "id": "fe83f19290338687",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-01T12:32:54.540598Z",
     "start_time": "2025-07-01T12:32:54.275175Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Read in documents using LangChain's loaders\n",
    "# Take everything in all the sub-folders of our knowledgebase\n",
    "\n",
    "folders = glob.glob(\"knowledge-base/*\")\n",
    "\n",
    "# With thanks to CG and Jon R, students on the course, for this fix needed for some users\n",
    "text_loader_kwargs = {'encoding': 'utf-8'}\n",
    "# If that doesn't work, some Windows users might need to uncomment the next line instead\n",
    "# text_loader_kwargs={'autodetect_encoding': True}\n",
    "\n",
    "documents = []\n",
    "for folder in folders:\n",
    "    doc_type = os.path.basename(folder)\n",
    "    loader = DirectoryLoader(folder, glob=\"**/*.md\", loader_cls=TextLoader, loader_kwargs=text_loader_kwargs)\n",
    "    folder_docs = loader.load()\n",
    "    for doc in folder_docs:\n",
    "        doc.metadata[\"doc_type\"] = doc_type\n",
    "        documents.append(doc)"
   ],
   "id": "46b3fc709f0b2b03",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-01T12:32:55.426323Z",
     "start_time": "2025-07-01T12:32:55.418776Z"
    }
   },
   "cell_type": "code",
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200\n",
    ")\n",
    "chunks = text_splitter.split_documents(documents)"
   ],
   "id": "1065ddf3c5ddfb6c",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-01T12:32:55.446350Z",
     "start_time": "2025-07-01T12:32:55.437888Z"
    }
   },
   "cell_type": "code",
   "source": "len(chunks)",
   "id": "b79c97855ed34a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "123"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-01T12:32:55.486587Z",
     "start_time": "2025-07-01T12:32:55.482405Z"
    }
   },
   "cell_type": "code",
   "source": [
    "doc_types = set(chunk.metadata['doc_type'] for chunk in chunks)\n",
    "print(f\"Document types found: {', '.join(doc_types)}\")"
   ],
   "id": "19b008953a0fb30a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document types found: company, products, employees, contracts\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-01T12:32:55.550623Z",
     "start_time": "2025-07-01T12:32:55.547303Z"
    }
   },
   "cell_type": "code",
   "source": "os.environ['OPENAI_API_KEY'] = os.getenv('OPENAI_API_KEY', 'your-key-if-not-using-env')",
   "id": "9f4c3408677d1965",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-01T13:13:50.977871Z",
     "start_time": "2025-07-01T13:13:46.419545Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "# Load embedding model\n",
    "embedding_model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=embedding_model_name,\n",
    ")\n",
    "\n",
    "# Create FAISS vector store\n",
    "vectorstore = FAISS.from_documents(chunks, embeddings)\n",
    "\n",
    "# Save and reload the vector store\n",
    "vectorstore.save_local(\"faiss_index_\")\n",
    "persisted_vectorstore = FAISS.load_local(\"faiss_index_\", embeddings, allow_dangerous_deserialization=True)\n",
    "\n",
    "# Create a retriever\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"score_threshold\": 0.7})"
   ],
   "id": "5c5e90135a05bd14",
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-01T12:55:56.163186Z",
     "start_time": "2025-07-01T12:55:54.583074Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# from openai import OpenAI\n",
    "#\n",
    "# client = OpenAI(base_url=\"http://127.0.0.1:1234/v1\", api_key=\"lm-studio\")\n",
    "# MODEL = \"dolphin3.0-llama3.2-3b\"\n",
    "#\n",
    "# response = client.chat.completions.create(\n",
    "#     model=MODEL,\n",
    "#     messages=[\n",
    "#         {\"role\": \"user\", \"content\": \"give me a joke\"}\n",
    "#     ]\n",
    "# )\n",
    "#\n",
    "# print(response.choices[0].message.content)\n"
   ],
   "id": "67ccfc5c556133d7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Of course! Here's a joke for you:\n",
      "\n",
      "Why did the computer run away from the wall?\n",
      "\n",
      "Because it was afraid of the firewall!\n",
      "\n",
      "I hope you enjoyed that one! If you need help with anything else, just let me know. I'm here to assist you.\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-01T14:05:29.016398Z",
     "start_time": "2025-07-01T14:05:28.671733Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from openai import OpenAI\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "# LM Studio client\n",
    "client = OpenAI(base_url=\"http://127.0.0.1:1234/v1\", api_key=\"lm-studio\")\n",
    "MODEL = \"dolphin3.0-llama3.2-3b\"\n"
   ],
   "id": "d291798509873456",
   "outputs": [],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-01T14:24:16.722711Z",
     "start_time": "2025-07-01T14:24:16.717685Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def format_history(chat_history):\n",
    "    \"\"\"Format chat history as a list of OpenAI-style messages.\"\"\"\n",
    "    return [{\"role\": msg[\"role\"], \"content\": msg[\"content\"]} for msg in chat_history]\n",
    "\n",
    "def build_messages(history, context, query):\n",
    "    \"\"\"Construct system + user messages for OpenAI\"\"\"\n",
    "    system_prompt = \"\"\"\n",
    "You are a helpful assistant for the website Metropolis.\n",
    "Only use the information provided in the CONTEXT below to answer the user's question.\n",
    "If the answer is not in the context, respond with: \"I don't know based on the documents.\"\n",
    "Never make up answers.\n",
    "\n",
    "CONTEXT:\n",
    "\"\"\" + context\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        *format_history(history),\n",
    "        {\"role\": \"user\", \"content\": query}\n",
    "    ]\n",
    "    return messages\n"
   ],
   "id": "f0abac74436b5ff8",
   "outputs": [],
   "execution_count": 67
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-01T14:24:18.369842Z",
     "start_time": "2025-07-01T14:24:18.365673Z"
    }
   },
   "cell_type": "code",
   "source": "conversation_history = []",
   "id": "46ec1c62550e2eba",
   "outputs": [],
   "execution_count": 68
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-01T14:24:20.919620Z",
     "start_time": "2025-07-01T14:24:20.914835Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_rag_response(query: str) -> str:\n",
    "    # 1. Get relevant docs\n",
    "    docs = retriever.invoke(query)\n",
    "    context = \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "    # 2. Build message list\n",
    "    messages = build_messages(conversation_history, context, query)\n",
    "    # 3. Call LLM via OpenAI-compatible API\n",
    "    response = client.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=messages,\n",
    "        temperature=0.0\n",
    "    )\n",
    "    answer = response.choices[0].message.content.strip()\n",
    "\n",
    "    # 4. Update global conversation history\n",
    "    conversation_history.append({\"role\": \"user\", \"content\": query})\n",
    "    conversation_history.append({\"role\": \"assistant\", \"content\": answer})\n",
    "\n",
    "    return answer"
   ],
   "id": "48c8554cc57f48b2",
   "outputs": [],
   "execution_count": 69
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-01T14:24:36.016012Z",
     "start_time": "2025-07-01T14:24:36.010913Z"
    }
   },
   "cell_type": "code",
   "source": "conversation_history",
   "id": "79fcf845c4dcb165",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'user', 'content': \"I'm abdou belhadj\"},\n",
       " {'role': 'assistant', 'content': '\"I don\\'t know based on the documents.\"'},\n",
       " {'role': 'user', 'content': 'Hello !'},\n",
       " {'role': 'assistant', 'content': '\"Hello! How can I assist you today?\"'}]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 73
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-01T14:25:23.936139Z",
     "start_time": "2025-07-01T14:25:21.028519Z"
    }
   },
   "cell_type": "code",
   "source": [
    "question = \"what are the services that metropolis provide?\"\n",
    "response = get_rag_response(question)\n",
    "print(\"🧠\", response)"
   ],
   "id": "15d745222729d2a3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧠 Based on the context provided and the information available about Metropolis, here are some of the services they may offer:\n",
      "\n",
      "1. **Information and Assistance**: They provide assistance to users by answering questions and providing information based on the documents provided in the context.\n",
      "\n",
      "2. **Helpful Assistant for the Website**: They act as a helpful assistant for the website Metropolis, aiming to assist users with their inquiries and needs.\n",
      "\n",
      "3. **Document-Based Answers**: Their answers are always based on the information provided in the context, ensuring that they provide accurate and relevant responses.\n",
      "\n",
      "4. **No Making Up Answers**: They strictly adhere to the information provided in the context without making up any answers or creating hypothetical scenarios.\n",
      "\n",
      "5. **Helpful and Professional**: They aim to be helpful and professional in their interactions with users, providing assistance and guidance as needed.\n",
      "\n",
      "If you have any specific questions or need further assistance, please let me know how I can help you today!\n"
     ]
    }
   ],
   "execution_count": 77
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-01T14:22:21.823561Z",
     "start_time": "2025-07-01T14:22:21.819321Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# # Initialize conversation history\n",
    "# conversation_history = []\n",
    "#\n",
    "# # Ask a question\n",
    "# query = \"who are you\"\n",
    "#\n",
    "# # Get relevant docs\n",
    "# docs = retriever.invoke(query)\n",
    "# context = \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "#\n",
    "# # Build messages\n",
    "# messages = build_messages(conversation_history, context, query)\n",
    "#\n",
    "# # Send to LM Studio via OpenAI API\n",
    "# response = client.chat.completions.create(\n",
    "#     model=MODEL,\n",
    "#     messages=messages,\n",
    "#     temperature=0.0\n",
    "# )\n",
    "#\n",
    "# answer = response.choices[0].message.content.strip()\n",
    "#\n",
    "# # Print result\n",
    "# print(\"🧠\", answer)\n",
    "#\n",
    "# # Update conversation history\n",
    "# conversation_history.append({\"role\": \"user\", \"content\": query})\n",
    "# conversation_history.append({\"role\": \"assistant\", \"content\": answer})\n"
   ],
   "id": "9e72b200f66ff675",
   "outputs": [],
   "execution_count": 62
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "d9436d33db93314"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
